{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian model selection and linear regression\n",
    "\n",
    "This notebook uses [Bayesian selection for linear regression with basis functions](https://arxiv.org/abs/1512.04823) in order to (partially) answer [question #2231975](https://math.stackexchange.com/questions/2231975/interpolating-a-given-data-by-a-simple-function/2232010#2232010) in Math StackExchange.\n",
    "\n",
    "The necessary code can be found in [bitbucket](https://bitbucket.org/mdbenito/modelselection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "from Hypotheses import *\n",
    "from ModelSelection import LinearRegression\n",
    "from Plots import updateMAPFitPlot, updateProbabilitiesPlot\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the necessary modules, we load data and normalize it to have zero mean and variance 1. This is required to avoid numerical issues: for large values of the target values, some probabilities in the computations become zero because of the exponential function ($e^{-t}$ becomes almost zero for relatively small values of $t$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('data-2231875.txt', delimiter=',', skiprows=1)\n",
    "data[:,1] = preprocessing.scale(data[:,1])\n",
    "pl.title(\"The (normalized) dataset\")\n",
    "_ = pl.plot(data[:,0], data[:,1])\n",
    "#pl.savefig('data.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now prepare some set of hypothesis spaces to be tested against each other. Because it's easy and alrady implemented in the repo, we take two polynomial and two trigonometric families of basis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma = data[:, 1].std()  # observation noise sigma (should be approx. 1 after scaling)\n",
    "hc = HypothesisCollection()\n",
    "hc.append(PolynomialHypothesis(M=6, variance=2, noiseVariance=sigma**2))\n",
    "hc.append(PolynomialHypothesis(M=8, variance=2, noiseVariance=sigma**2))\n",
    "hc.append(TrigonometricHypothesis(halfM=4, variance=2, noiseVariance=sigma**2))\n",
    "hc.append(TrigonometricHypothesis(halfM=6, variance=2, noiseVariance=sigma**2))\n",
    "\n",
    "lr = LinearRegression(hc, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now perform bayesian updates to our belief in each hypothesis space. Each data point is fed to the `LinearRegression` object which then performs:\n",
    "1. Estimation of the weights for each hypothesis.\n",
    "2. Computation of the posterior probability of each hypothesis, given the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ymin, ymax = min(data[:,1]), max(data[:,1])\n",
    "# Looping is ugly, but it is what it is! :P\n",
    "for x, y in data:\n",
    "    lr.update(x, y)\n",
    "\n",
    "# MAP values for the weights w_j\n",
    "wmap = [param.mean for param in lr.parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = pl.subplots(2)\n",
    "updateMAPFitPlot(ax1, lr.XHist, lr.hypotheses, wmap, 0.005) \n",
    "ax1.plot(lr.XHist, lr.THist, 'k+', ms=4, alpha=0.5)  # plot the data points\n",
    "ax1.set_title(\"Data and MAP fits\")\n",
    "updateProbabilitiesPlot(ax2, lr)\n",
    "ax2.set_title(\"Incremental model probability\")\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "#pl.savefig('mapfits.svg')\n",
    "_ = pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winner among the hypotheses proposed is clearly the Trigonometric hypothesis  ($H_2$) with $M=8$ basis functions:\n",
    "\n",
    "$$\\phi_j (x) = \\cos (\\pi jx)\\  \\text{ for }\\ j = 0, \\ldots, M - 1,$$\n",
    "\n",
    "so that our best candidate is\n",
    "\n",
    "$$f(x) = \\sum_{j=0}^8 w_j \\phi_j (x). $$\n",
    "\n",
    "The specific values of the weights $w_j$ are taken from from the _a posteriori_ distribution computed (Gaussian since we started with a Gaussian prior). Their MAP values are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmap[2].round(2).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the model comparison rejects the seemingly better `Trig11` hypothesis at around half the dataset, and leans in favor of `Trig7` which looks like a poorer fit. This is because model complexity is penalized. `Trig11` is a wildly oscillating polynomial beyond the interval considered whereas `Trig7` is a bit more tame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(-1,2,200)\n",
    "for h, w, l in zip(lr.hypotheses[2:], wmap[2:], ['Trig7', 'Trig11']):\n",
    "    pl.plot(xx, [np.dot(h.evaluate(x).flatten(), w) for x in xx], label=l)\n",
    "pl.title(\"Complexity in competing hypotheses\")\n",
    "_ = pl.legend()\n",
    "#pl.savefig('complexity.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't mean however that either is a good fit (nor that extrapolating beyond the range of the dataset would be wise, no matter how good the fit is), only that one is better than the other. At this point we would need to try more hypothesis spaces, perhaps ones with functions with compact support at multiple scales and locations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
